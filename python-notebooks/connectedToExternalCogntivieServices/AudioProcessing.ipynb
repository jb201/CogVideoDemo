{"cells":[{"cell_type":"code","source":["import time\nimport wave\nimport azure.cognitiveservices.speech as speechsdk\nimport json\nfrom pyspark.sql.types import *\nfrom pyspark.sql import *\nprint(speechsdk.__version__)\n\nfields = [StructField(\"Id\",StringType(), True),StructField(\"Offset\", IntegerType(), True), StructField(\"Duration\", IntegerType(), True), StructField(\"Text\", StringType(), True)]\nschema = StructType(fields)\n\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["def speech_recognition_with_pull_stream(myFile, myId):\n    \"\"\"gives an example how to use a pull audio stream to recognize speech from a custom audio\n    source\"\"\"\n    \n    class WavFileReaderCallback(speechsdk.audio.PullAudioInputStreamCallback):\n        \"\"\"Example class that implements the Pull Audio Stream interface to recognize speech from\n        an audio file\"\"\"\n        def __init__(self, filename: str):\n            super().__init__()\n            self._file_h = wave.open(filename, mode=None)\n            self.sample_width = self._file_h.getsampwidth()\n            assert self._file_h.getnchannels() == 1\n            assert self._file_h.getsampwidth() == 2\n            assert self._file_h.getframerate() == 16000\n            assert self._file_h.getcomptype() == 'NONE'\n\n        def read(self, buffer: memoryview) -> int:\n            \"\"\"read callback function\"\"\"\n            size = buffer.nbytes\n            frames = self._file_h.readframes(size // self.sample_width)\n\n            buffer[:len(frames)] = frames\n\n            return len(frames)\n\n        def close(self):\n            \"\"\"close callback function\"\"\"\n            self._file_h.close()\n\n    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n\n    # specify the audio format\n    wave_format = speechsdk.audio.AudioStreamFormat(samples_per_second=16000, bits_per_sample=16,\n            channels=1)\n\n    # setup the audio stream\n    callback = WavFileReaderCallback(myFile)\n    stream = speechsdk.audio.PullAudioInputStream(callback, wave_format)\n    audio_config = speechsdk.audio.AudioConfig(stream=stream)\n    \n    # instantiate the speech recognizer with pull stream input\n    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n    print(myId)\n    done = False\n    # create an empty dataframe for storing results\n    \n    #dfu = spark.createDataFrame(data=[], schema=schema)\n    #dfu.show()\n    dfu = spark.createDataFrame(data=[], schema=schema)\n    # empty the temp file \n    dfu.write.mode('overwrite').parquet('temp_parq')\n    \n    def stop_cb(evt):\n        \"\"\"callback that stops continuous recognition upon receiving an event `evt`\"\"\"\n        print('CLOSING on {}'.format(evt))\n        speech_recognizer.stop_continuous_recognition()\n        nonlocal done\n        done = True\n\n    def recognized_cb(evt):\n        \"\"\" callback that \"\"\"        \n        newRow = Row(Id=myId, Offset=evt.result.offset, Duration=evt.result.duration, Text=evt.result.text)\n        df = spark.createDataFrame(data=[newRow], schema=schema)\n        # writing to a temp parquet file because having trouble persisting from the callback \n        df.write.mode('append').parquet('temp_parq')\n    \n    # Connect callbacks to the events fired by the speech recognizer\n    speech_recognizer.recognized.connect(lambda evt: recognized_cb( evt))\n\n    speech_recognizer.session_started.connect(lambda evt: print('SESSION STARTED: {}'.format(evt)))\n    speech_recognizer.session_stopped.connect(lambda evt: print('SESSION STOPPED {}'.format(evt)))\n    speech_recognizer.canceled.connect(lambda evt: print('CANCELED {}'.format(evt)))\n    \n    # stop continuous recognition on either session stopped or canceled events\n    speech_recognizer.session_stopped.connect(stop_cb)\n    speech_recognizer.canceled.connect(stop_cb)\n\n    # Start continuous speech recognition\n    speech_recognizer.start_continuous_recognition()\n\n    while not done:\n        time.sleep(.5)\n\n    s = spark.read.parquet(\"temp_parq\")\n    return s\n   \n    "],"metadata":{},"outputs":[],"execution_count":2}],"metadata":{"name":"AudioProcessing","notebookId":270093129287872},"nbformat":4,"nbformat_minor":0}

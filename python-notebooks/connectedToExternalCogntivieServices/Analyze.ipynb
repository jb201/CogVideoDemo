{"cells":[{"cell_type":"code","source":["%sql\nselect * from videos where id = '8eb07220-bd39-44c1-9a10-94328ee79e1c'\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["%sql\nSET vkey='8eb07220-bd39-44c1-9a10-94328ee79e1c'"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["%sql\nselect * from tempfacetable where videoId = '8eb07220-bd39-44c1-9a10-94328ee79e1c'\norder by frameNum\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["%sql\nselect \navg(torchAnger) anger, avg(torchDisgust) disgust, avg(torchFear) fear, avg(torchHappy) happy, avg(torchSad) sad, avg(torchSurprise) surprise, avg(torchNeutral) neutral from tempfacetable \nwhere videoId = '8eb07220-bd39-44c1-9a10-94328ee79e1c'"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["%sql\nselect avg(faceAttributes_emotion_anger) anger,avg(faceAttributes_emotion_contempt) contempt,avg(faceAttributes_emotion_disgust) disgust, avg(faceAttributes_emotion_fear) fear, avg(faceAttributes_emotion_happiness) hapiness, avg(faceAttributes_emotion_neutral) neutral, avg(faceAttributes_emotion_sadness) sadness, avg(faceAttributes_emotion_surprise) surprise\n from tempfacetable \nwhere videoId = '8eb07220-bd39-44c1-9a10-94328ee79e1c'"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["%sql\nselect * from tempAudioTable where id = '8eb07220-bd39-44c1-9a10-94328ee79e1c'\norder by offset "],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["%sql\nselect id, offset,duration, offset/10000000  secOffset, duration/10000000 durationOffset, text from tempAudioTable where id = '79dd1b01-bb82-4985-a6d0-de2ec2775b58'\n\norder by offset "],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["I asked my son to make a face like your brother just took his favorite toy.   \n\nOffset of this question started around \t65100000 with a duration 18600000.  Those are in 100-nanosecond units.  \nLets look at emotion before and after using sql queries.  \n\nQuestion ends at approximately 8.37 seconds in to the video.   I am taking 3 samples per second, so I will look from 8.5 to 10.\n\nFor before I will look at 5.0 to 8.5"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["%sql\nselect avg(faceAttributes_emotion_anger) anger,avg(faceAttributes_emotion_contempt) contempt,avg(faceAttributes_emotion_disgust) disgust, avg(faceAttributes_emotion_fear) fear, avg(faceAttributes_emotion_happiness) hapiness, avg(faceAttributes_emotion_neutral) neutral, avg(faceAttributes_emotion_sadness) sadness, avg(faceAttributes_emotion_surprise) surprise  from tempfacetable \nwhere videoId = '8eb07220-bd39-44c1-9a10-94328ee79e1c'\nand frameNum > 255 and framenum < 360\nunion\nselect avg(faceAttributes_emotion_anger) anger,avg(faceAttributes_emotion_contempt) contempt,avg(faceAttributes_emotion_disgust) disgust, avg(faceAttributes_emotion_fear) fear, avg(faceAttributes_emotion_happiness) hapiness, avg(faceAttributes_emotion_neutral) neutral, avg(faceAttributes_emotion_sadness) sadness, avg(faceAttributes_emotion_surprise) surprise  from tempfacetable \nwhere videoId = '8eb07220-bd39-44c1-9a10-94328ee79e1c'\nand frameNum < 255\n"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["%sql\nselect avg(faceAttributes_emotion_anger) anger,avg(faceAttributes_emotion_contempt) contempt,avg(faceAttributes_emotion_disgust) disgust, avg(faceAttributes_emotion_fear) fear, avg(faceAttributes_emotion_happiness) hapiness, avg(faceAttributes_emotion_neutral) neutral, avg(faceAttributes_emotion_sadness) sadness, avg(faceAttributes_emotion_surprise) surprise \nfrom tempfacetable \nwhere videoId = '8eb07220-bd39-44c1-9a10-94328ee79e1c'\n"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["%sql\nselect framenum, faceAttributes_emotion_happiness, torchHappy from tempfacetable \nwhere videoId = '8eb07220-bd39-44c1-9a10-94328ee79e1c'\norder by framenum"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["%sql\nselect framenum, faceAttributes_emotion_sadness, torchSad from tempfacetable \nwhere videoId = '8eb07220-bd39-44c1-9a10-94328ee79e1c'\norder by framenum"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["%sql\nselect framenum, faceAttributes_emotion_anger, torchanger from tempfacetable \nwhere videoId = '35dd610e-8c63-4ad0-ad14-c0bf8cc8b54f'\norder by framenum"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["%sql\nselect * from tempfacetable \nwhere videoId = '8eb07220-bd39-44c1-9a10-94328ee79e1c'\nand framenum = 280\norder by framenum"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["myStuff = spark.table(\"tempfacetable\")\n\ndisplay(myStuff.select('torchFear').filter(\"videoId='8eb07220-bd39-44c1-9a10-94328ee79e1c'\").collect())"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["# displayVid(): Shows video from mounted cloud storage\ndef displayVid(filepath):\n  return displayHTML(\"\"\"\n  <video width=\"480\" height=\"320\" controls>\n  <source src=\"/dbfs/%s\" type=\"video/mp4\">\n  </video>\n  \"\"\" % filepath)\n\n# displayDbfsVid(): Shows video from DBFS\ndef displayDbfsVid(filepath):\n  return displayHTML(\"\"\"\n  <video width=\"480\" height=\"320\" controls>\n  <source src=\"/dbfs/%s\" type=\"video/mp4\">\n  </video>\n  \"\"\" % filepath)\n\n# displayImg(): Shows image from dbfs/cloud storage\ndef displayImg(filepath):\n  dbutils.fs.cp(filepath, \"FileStore/%s\" % filepath)\n  return displayHTML(\"\"\"\n  <img src=\"/files/%s\">\n  \"\"\" % filepath)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["displayImg('mnt/bs/xyz/Berry-1.jpg')"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["import cv2\ndef grab_a_sample_frames(video_filename, frameNum, left, top, height, width):\n    \"\"\"Extract frames from video\"\"\"\n    cap = cv2.VideoCapture(video_filename)\n    video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n    cap.set(cv2.CAP_PROP_POS_FRAMES, frameNum-1)\n    res, image = cap.read()\n    print(image)\n    x = left\n    y= top\n    h = height\n    w = width\n    crop_img = image[y:y+h, x:x+w]\n    return crop_img"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["sample = grab_a_sample_frames('/dbfs/mnt/bs/IncomingVideos/completed/greyson_faces1._v7.mp4', 280, 846,322,242,242)\nimg = Image.fromarray(sample, 'RGB')\nimg.save('/dbfs/mnt/bs/xyz/b3.jpg')\ndisplayImg('mnt/bs/xyz/b3.jpg')"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["displayImg('mnt/bs/xyz/b1.jpg')"],"metadata":{},"outputs":[],"execution_count":21}],"metadata":{"name":"Analyze","notebookId":270093129287875},"nbformat":4,"nbformat_minor":0}
